[project]
name = "inference-modules-vllm"
version = "0.1.0"
description = "Add your description here"
readme = "README.md"
requires-python = ">=3.11, <3.13"
dependencies = [
    "llm-jp-eval-inference",
    "torch>=2.6.0",
    "transformers>=4.57.2",
    "vllm==0.11.2",
]

[tool.uv]
no-binary-package = ["pyairports"]

[tool.uv.sources]
llm-jp-eval-inference = { path = "../../", editable = true }
